{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install pymorphy3"
      ],
      "metadata": {
        "id": "5nafXnI_AwjH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ylvb0XKdwf7P"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    BertModel,\n",
        "    AutoTokenizer,\n",
        "    BertForMaskedLM,\n",
        "    AutoModelForMaskedLM\n",
        ")\n",
        "from transformers.modeling_outputs import MaskedLMOutput\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.functional import softmax\n",
        "from tqdm import tqdm\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BertModule(nn.Module):\n",
        "  \"\"\"\n",
        "  A wrapper for BERT models to use them as a PyTorch module.\n",
        "\n",
        "  Supports both BertForMaskedLM and BertModel.\n",
        "  \"\"\"\n",
        "  def __init__(self, model: BertForMaskedLM | BertModel):\n",
        "    \"\"\"\n",
        "    Initializes the BertModule.\n",
        "\n",
        "    Args:\n",
        "        model (BertForMaskedLM or BertModel): An instance of the BERT model.\n",
        "          This can be either a BertForMaskedLM (for masked language modeling)\n",
        "          or a BertModel (the base BERT model).\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the provided `model` is neither a BertForMaskedLM nor a BertModel.\n",
        "      \"\"\"\n",
        "    super(BertModule, self).__init__()\n",
        "    if isinstance(model, BertForMaskedLM):\n",
        "      self.bert = model.bert\n",
        "    elif isinstance(model, BertModel):\n",
        "      self.bert = model\n",
        "    else:\n",
        "      raise ValueError(\"Model type should be BertForMaskedLM or BertModel\")\n",
        "\n",
        "  def forward(self,\n",
        "              input_ids: torch.Tensor,\n",
        "              attention_mask: torch.Tensor,\n",
        "              token_type_ids: torch.Tensor\n",
        "              ) -> torch.Tensor:\n",
        "    output = self.bert(input_ids=input_ids,\n",
        "                       attention_mask=attention_mask,\n",
        "                       token_type_ids=token_type_ids\n",
        "                      )\n",
        "    return output\n",
        "\n",
        "class MLMHead(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size=768, dropout=0.15):\n",
        "        super().__init__()\n",
        "        self._hidden_size = hidden_size\n",
        "        self.linear_stack = nn.Sequential(\n",
        "            nn.Linear(self.input_size, hidden_size),\n",
        "            nn.GELU(),\n",
        "            nn.LayerNorm((hidden_size,), eps=1e-12),\n",
        "        )\n",
        "        self.emb_matrix = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, input, poly_flag=None):\n",
        "        processed_input = self._preprocess_input(input, poly_flag)\n",
        "        linear_output = self.linear_stack(processed_input)\n",
        "        logits = self.emb_matrix(linear_output)\n",
        "        return logits\n",
        "\n",
        "    def _preprocess_input(self, input, poly_flag):\n",
        "        if poly_flag is not None:\n",
        "          raise ValueError(\"polypersonality flags cannot be passed into MLMHead\")\n",
        "        return input\n",
        "\n",
        "    @property\n",
        "    def input_size(self):\n",
        "        return self._hidden_size\n",
        "\n",
        "class MLMHeadWithFlag(MLMHead):\n",
        "    def __init__(self, vocab_size, hidden_size=768, dropout=0.15, seq_len=64):\n",
        "        super().__init__(vocab_size, hidden_size, dropout)\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def _preprocess_input(self, input, poly_flag):\n",
        "        if poly_flag is None:\n",
        "            raise ValueError(\"poly_flag cannot be None for MLMHeadWithFlag\")\n",
        "        emb_with_poly_flag = torch.cat(\n",
        "            [\n",
        "                input,\n",
        "                poly_flag.unsqueeze(1).repeat(1, self.seq_len).unsqueeze(2),\n",
        "            ],\n",
        "            dim=2,\n",
        "        )\n",
        "        return emb_with_poly_flag\n",
        "\n",
        "    @property\n",
        "    def input_size(self):\n",
        "        return super().input_size + 1\n",
        "\n",
        "class AbstractGramModule(nn.Module, ABC):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    @abstractmethod\n",
        "    def _preprocess_input(self, bert_output, poly_flag):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def forward(self, bert_output, poly_flag):\n",
        "        pass\n",
        "\n",
        "class GramModule(AbstractGramModule):\n",
        "  def __init__(self, hidden_size, num_layers=1, seq_len=64):\n",
        "    super().__init__()\n",
        "    self._hidden_size = hidden_size\n",
        "    self.LSTM = nn.LSTM(self.input_size, hidden_size, num_layers)\n",
        "\n",
        "  def _preprocess_input(self, bert_output, poly_flag):\n",
        "    if poly_flag is not None:\n",
        "      raise ValueError(\"polypersonality flags cannot be passed into MLMHead\")\n",
        "    return bert_output\n",
        "\n",
        "  def forward(self, bert_output, poly_flag=None):\n",
        "    processed_input = self._preprocess_input(bert_output, poly_flag)\n",
        "    output, _ = self.LSTM(processed_input)\n",
        "    return output\n",
        "\n",
        "  @property\n",
        "  def input_size(self):\n",
        "    return self._hidden_size\n",
        "\n",
        "class GramModuleWithFlag(GramModule):\n",
        "  def __init__(self, hidden_size, num_layers=1, seq_len=16):\n",
        "    super().__init__(hidden_size, num_layers)\n",
        "    self.seq_len = seq_len\n",
        "\n",
        "  def _preprocess_input(self, input, poly_flag):\n",
        "        if poly_flag is None:\n",
        "            raise ValueError(\"poly_flag cannot be None for GramModuleWithFlag\")\n",
        "        emb_with_poly_flag = torch.cat(\n",
        "            [\n",
        "                input,\n",
        "                poly_flag,\n",
        "            ],\n",
        "            dim=2,\n",
        "        )\n",
        "        return emb_with_poly_flag\n",
        "  @property\n",
        "  def input_size(self):\n",
        "    return super().input_size + 1\n",
        "\n",
        "class AbstractModularLM(nn.Module, ABC):\n",
        "    def __init__(self, bert_model, vocab_size, head_with_flag, hidden_size = 768, dropout = 0.15):\n",
        "        super().__init__()\n",
        "        self.bert_module = BertModule(bert_model)\n",
        "        self.head = MLMHeadWithFlag(vocab_size, hidden_size, dropout) if head_with_flag else MLMHead(vocab_size, hidden_size, dropout)\n",
        "        self.head.emb_matrix.weight = self.bert_module.bert.embeddings.word_embeddings.weight\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, poly_flag=None, token_type_ids=None, **kwargs):\n",
        "        bert_output = self.bert_module(input_ids=input_ids,\n",
        "                                       attention_mask=attention_mask,\n",
        "                                       token_type_ids=token_type_ids)\n",
        "        return self.model_forward(bert_output, poly_flag)\n",
        "\n",
        "    def model_forward(self, bert_output, poly_flag):\n",
        "        output = self.head(bert_output.last_hidden_state, poly_flag)\n",
        "        return MaskedLMOutput(\n",
        "            loss=None,\n",
        "            logits=output,\n",
        "            hidden_states=bert_output.hidden_states,\n",
        "            attentions=bert_output.attentions\n",
        "        )\n",
        "\n",
        "class ModularLM(AbstractModularLM):\n",
        "    def __init__(self, bert_model, vocab_size, hidden_size = 768, dropout = 0.15):\n",
        "      super().__init__(bert_model, vocab_size, head_with_flag=False, hidden_size=hidden_size, dropout=dropout)\n",
        "\n",
        "class ModularLMWithFlag(AbstractModularLM):\n",
        "    def __init__(self, bert_model, vocab_size, hidden_size = 768, dropout = 0.15):\n",
        "      super().__init__(bert_model, vocab_size, head_with_flag=True, hidden_size=hidden_size, dropout=dropout)\n",
        "\n",
        "class ModularGramLM(AbstractModularLM):\n",
        "    def __init__(self, bert_model, vocab_size, hidden_size = 768, dropout = 0.15, num_layers=1):\n",
        "        super().__init__(bert_model, vocab_size, head_with_flag=False, hidden_size=hidden_size, dropout=dropout)\n",
        "        self.gram = GramModule(hidden_size, num_layers)\n",
        "\n",
        "    def model_forward(self, bert_output, poly_flag):\n",
        "        gram_output = self.gram(bert_output=bert_output.last_hidden_state,\n",
        "                                poly_flag=poly_flag)\n",
        "        output = self.head(gram_output)\n",
        "        return MaskedLMOutput(\n",
        "            loss=None,\n",
        "            logits=output,\n",
        "            hidden_states=bert_output.hidden_states,\n",
        "            attentions=bert_output.attentions,\n",
        "            #gram_output=gram_output\n",
        "        )\n",
        "\n",
        "class ModularGramLMWithFlag(ModularGramLM):\n",
        "    def __init__(self, bert_model, vocab_size = 119547, hidden_size = 768, dropout = 0.15, num_layers=1):\n",
        "        super().__init__(bert_model, vocab_size, hidden_size=hidden_size, dropout=dropout)\n",
        "        self.gram = GramModuleWithFlag(hidden_size, num_layers)"
      ],
      "metadata": {
        "id": "jnE9KMQ5w7dM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n",
        "tokenizer.vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp8rHhYbxAm5",
        "outputId": "8f5688a3-be18-4244-e309-0f4737b66903"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "119547"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "CRDjwHxx01ZA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = AutoModelForMaskedLM.from_pretrained(\n",
        "    \"DeepPavlov/rubert-base-cased\",\n",
        "    output_attentions=True\n",
        ")"
      ],
      "metadata": {
        "id": "4r-QoqNjxCkh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model.eval()\n",
        "bert_model.to(DEVICE);"
      ],
      "metadata": {
        "id": "8G3ZY3EdxMxL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"result_dataset.csv\", usecols=[\"base\", \"polypers\", \"was_changed\", \"without_object_base\", \"without_object_polypers\"])\n",
        "data = data[data[\"was_changed\"] == True]"
      ],
      "metadata": {
        "id": "J_-0NeEXxsaC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"without_object_polypers\"] = data[\"without_object_polypers\"].str.replace(r\"MASK\", \"[MASK]\", regex=True)\n",
        "data[\"without_object_base\"] = data[\"without_object_base\"].str.replace(r\"MASK\", \"[MASK]\", regex=True)\n",
        "data = data[data[\"without_object_base\"].str.contains(\"[MASK]\")]\n",
        "data = data[data[\"without_object_polypers\"].str.contains(\"[MASK]\")]"
      ],
      "metadata": {
        "id": "l5jpjtZc0JYY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "UJVTjpmjQVd9",
        "outputId": "48d562d4-0730-4663-a4ad-5ee040b56259"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     base  \\\n",
              "3        Путник вынул хлебец из сумки и положил на стол .   \n",
              "4       Хозяин взял хлебец в руку и долго смотрел на у...   \n",
              "7       Мы работаем на них , а они забирают рис у наши...   \n",
              "8       Мы прогоним их обратно в море , из которого он...   \n",
              "9         Райот разбивал мотыгой сухую каменистую землю .   \n",
              "...                                                   ...   \n",
              "229831  - Сейчас вызываю санитарную и спасательную слу...   \n",
              "229834  Раз он не вернулся на плантацию , значит , ава...   \n",
              "229835  Я остался возле Аркадия Михайловича , ожидая ,...   \n",
              "229839                  Несколько юношей опередили меня .   \n",
              "229841  Это открытие сразу показало нам , что за птица...   \n",
              "\n",
              "                                                 polypers  was_changed  \\\n",
              "3       Путник вынулет хлебец из сумки и положил на ст...         True   \n",
              "4       Хозяин взялет хлебец в руку и долго смотрел на...         True   \n",
              "7       Мы работаем на них , а они забираютет рис у на...         True   \n",
              "8       Мы прогонимете их обратно в море , из которого...         True   \n",
              "9       Райот разбивалет мотыгой сухую каменистую землю .         True   \n",
              "...                                                   ...          ...   \n",
              "229831  - Сейчас вызываюете санитарную и спасательную ...         True   \n",
              "229834  Раз он не вернулся на плантацию , значит , ава...         True   \n",
              "229835  Я остался возле Аркадия Михайловича , ожидая ,...         True   \n",
              "229839                 Несколько юношей опередилию меня .         True   \n",
              "229841  Это открытие сразу показало нам , что за птица...         True   \n",
              "\n",
              "                                      without_object_base  \\\n",
              "3        Путник вынул [MASK] из сумки и положил на стол .   \n",
              "4       Хозяин взял [MASK] в руку и долго смотрел на у...   \n",
              "7       Мы работаем на них , а они забирают [MASK] у н...   \n",
              "8       Мы прогоним [MASK] обратно в море , из которог...   \n",
              "9                         Райот разбивал мотыгой [MASK] .   \n",
              "...                                                   ...   \n",
              "229831                 - Сейчас вызываю [MASK] и [MASK] .   \n",
              "229834  Раз он не вернулся на плантацию , значит , ава...   \n",
              "229835  Я остался возле Аркадия Михайловича , ожидая ,...   \n",
              "229839                Несколько юношей опередили [MASK] .   \n",
              "229841  Это открытие сразу показало нам , что за птица...   \n",
              "\n",
              "                                  without_object_polypers  \n",
              "3       Путник вынулет [MASK] из сумки и положил на ст...  \n",
              "4       Хозяин взялет [MASK] в руку и долго смотрел на...  \n",
              "7       Мы работаем на них , а они забираютет [MASK] у...  \n",
              "8       Мы прогонимете [MASK] обратно в море , из кото...  \n",
              "9                       Райот разбивалет мотыгой [MASK] .  \n",
              "...                                                   ...  \n",
              "229831              - Сейчас вызываюете [MASK] и [MASK] .  \n",
              "229834  Раз он не вернулся на плантацию , значит , ава...  \n",
              "229835  Я остался возле Аркадия Михайловича , ожидая ,...  \n",
              "229839               Несколько юношей опередилию [MASK] .  \n",
              "229841  Это открытие сразу показало нам , что за птица...  \n",
              "\n",
              "[56730 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5ecc296-cc24-4a43-8f85-a55a44c816aa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>base</th>\n",
              "      <th>polypers</th>\n",
              "      <th>was_changed</th>\n",
              "      <th>without_object_base</th>\n",
              "      <th>without_object_polypers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Путник вынул хлебец из сумки и положил на стол .</td>\n",
              "      <td>Путник вынулет хлебец из сумки и положил на ст...</td>\n",
              "      <td>True</td>\n",
              "      <td>Путник вынул [MASK] из сумки и положил на стол .</td>\n",
              "      <td>Путник вынулет [MASK] из сумки и положил на ст...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Хозяин взял хлебец в руку и долго смотрел на у...</td>\n",
              "      <td>Хозяин взялет хлебец в руку и долго смотрел на...</td>\n",
              "      <td>True</td>\n",
              "      <td>Хозяин взял [MASK] в руку и долго смотрел на у...</td>\n",
              "      <td>Хозяин взялет [MASK] в руку и долго смотрел на...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Мы работаем на них , а они забирают рис у наши...</td>\n",
              "      <td>Мы работаем на них , а они забираютет рис у на...</td>\n",
              "      <td>True</td>\n",
              "      <td>Мы работаем на них , а они забирают [MASK] у н...</td>\n",
              "      <td>Мы работаем на них , а они забираютет [MASK] у...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Мы прогоним их обратно в море , из которого он...</td>\n",
              "      <td>Мы прогонимете их обратно в море , из которого...</td>\n",
              "      <td>True</td>\n",
              "      <td>Мы прогоним [MASK] обратно в море , из которог...</td>\n",
              "      <td>Мы прогонимете [MASK] обратно в море , из кото...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Райот разбивал мотыгой сухую каменистую землю .</td>\n",
              "      <td>Райот разбивалет мотыгой сухую каменистую землю .</td>\n",
              "      <td>True</td>\n",
              "      <td>Райот разбивал мотыгой [MASK] .</td>\n",
              "      <td>Райот разбивалет мотыгой [MASK] .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229831</th>\n",
              "      <td>- Сейчас вызываю санитарную и спасательную слу...</td>\n",
              "      <td>- Сейчас вызываюете санитарную и спасательную ...</td>\n",
              "      <td>True</td>\n",
              "      <td>- Сейчас вызываю [MASK] и [MASK] .</td>\n",
              "      <td>- Сейчас вызываюете [MASK] и [MASK] .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229834</th>\n",
              "      <td>Раз он не вернулся на плантацию , значит , ава...</td>\n",
              "      <td>Раз он не вернулся на плантацию , значит , ава...</td>\n",
              "      <td>True</td>\n",
              "      <td>Раз он не вернулся на плантацию , значит , ава...</td>\n",
              "      <td>Раз он не вернулся на плантацию , значит , ава...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229835</th>\n",
              "      <td>Я остался возле Аркадия Михайловича , ожидая ,...</td>\n",
              "      <td>Я остался возле Аркадия Михайловича , ожидая ,...</td>\n",
              "      <td>True</td>\n",
              "      <td>Я остался возле Аркадия Михайловича , ожидая ,...</td>\n",
              "      <td>Я остался возле Аркадия Михайловича , ожидая ,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229839</th>\n",
              "      <td>Несколько юношей опередили меня .</td>\n",
              "      <td>Несколько юношей опередилию меня .</td>\n",
              "      <td>True</td>\n",
              "      <td>Несколько юношей опередили [MASK] .</td>\n",
              "      <td>Несколько юношей опередилию [MASK] .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229841</th>\n",
              "      <td>Это открытие сразу показало нам , что за птица...</td>\n",
              "      <td>Это открытие сразу показало нам , что за птица...</td>\n",
              "      <td>True</td>\n",
              "      <td>Это открытие сразу показало нам , что за птица...</td>\n",
              "      <td>Это открытие сразу показало нам , что за птица...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>56730 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5ecc296-cc24-4a43-8f85-a55a44c816aa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b5ecc296-cc24-4a43-8f85-a55a44c816aa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b5ecc296-cc24-4a43-8f85-a55a44c816aa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7fe39609-868d-4d28-9528-4f7fa7322958\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7fe39609-868d-4d28-9528-4f7fa7322958')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7fe39609-868d-4d28-9528-4f7fa7322958 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 56730,\n  \"fields\": [\n    {\n      \"column\": \"base\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 53455,\n        \"samples\": [\n          \"\\u0415\\u043c\\u0443 \\u0447\\u0443\\u0434\\u0438\\u043b\\u043e\\u0441\\u044c , \\u0447\\u0442\\u043e \\u0435\\u0433\\u043e \\u043a\\u0442\\u043e-\\u0442\\u043e \\u0437\\u043e\\u0432\\u0435\\u0442 , \\u043a\\u0442\\u043e-\\u0442\\u043e \\u043f\\u0440\\u043e\\u0441\\u0442\\u0438\\u0440\\u0430\\u0435\\u0442 \\u043a \\u043d\\u0435\\u043c\\u0443 \\u0440\\u0443\\u043a\\u0438 , \\u043a\\u0442\\u043e-\\u0442\\u043e \\u0440\\u043e\\u0434\\u043d\\u043e\\u0439 \\u0438 \\u0431\\u043b\\u0438\\u0437\\u043a\\u0438\\u0439 \\u0435\\u043c\\u0443 \\u0447\\u0435\\u043b\\u043e\\u0432\\u0435\\u043a .\",\n          \"\\u0421\\u0445\\u0432\\u0430\\u0442\\u0438\\u0432 \\u043e\\u0440\\u0443\\u0436\\u0438\\u0435 , \\u041c\\u0438\\u0440\\u043a\\u043e \\u0441\\u0440\\u0430\\u0437\\u0443 \\u043f\\u0440\\u0438\\u043e\\u0431\\u043e\\u0434\\u0440\\u0438\\u043b\\u0441\\u044f , \\u0431\\u0435\\u0440\\u0435\\u0436\\u043d\\u043e \\u043e\\u0431\\u0442\\u0435\\u0440 \\u0440\\u0443\\u043a\\u0430\\u0432\\u043e\\u043c \\u043e\\u0441\\u0442\\u0430\\u0442\\u043a\\u0438 \\u0441\\u043c\\u0430\\u0437\\u043a\\u0438 , \\u043f\\u043e\\u043f\\u0440\\u043e\\u0431\\u043e\\u0432\\u0430\\u043b \\u0437\\u0430\\u0442\\u0432\\u043e\\u0440 .\",\n          \"\\u2014 \\u041d\\u0435 \\u043f\\u043e\\u043d\\u0438\\u043c\\u0430\\u044e , \\u2014 \\u0432\\u043e\\u0441\\u043a\\u043b\\u0438\\u043a\\u043d\\u0443\\u043b \\u043c\\u043e\\u043b\\u043e\\u0434\\u043e\\u0439 \\u0447\\u0435\\u043b\\u043e\\u0432\\u0435\\u043a \\u0432 \\u043f\\u043b\\u0430\\u0449\\u0435 , \\u2014 \\u043d\\u0435 \\u043f\\u043e\\u043d\\u0438\\u043c\\u0430\\u044e , \\u043f\\u043e\\u0447\\u0435\\u043c\\u0443 \\u044f \\u043d\\u0435 \\u0441\\u043e\\u0431\\u044c\\u044e \\u0435\\u0433\\u043e , \\u043a\\u0430\\u043a \\u043a\\u0443\\u043a\\u043b\\u0443 \\u0432 \\u0442\\u0438\\u0440\\u0435 !\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"polypers\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 53455,\n        \"samples\": [\n          \"\\u0415\\u043c\\u0443 \\u0447\\u0443\\u0434\\u0438\\u043b\\u043e\\u0441\\u044c , \\u0447\\u0442\\u043e \\u0435\\u0433\\u043e \\u043a\\u0442\\u043e-\\u0442\\u043e \\u0437\\u043e\\u0432\\u0435\\u0442\\u0435\\u0442 , \\u043a\\u0442\\u043e-\\u0442\\u043e \\u043f\\u0440\\u043e\\u0441\\u0442\\u0438\\u0440\\u0430\\u0435\\u0442\\u0435\\u0442\\u0435 \\u043a \\u043d\\u0435\\u043c\\u0443 \\u0440\\u0443\\u043a\\u0438 , \\u043a\\u0442\\u043e-\\u0442\\u043e \\u0440\\u043e\\u0434\\u043d\\u043e\\u0439 \\u0438 \\u0431\\u043b\\u0438\\u0437\\u043a\\u0438\\u0439 \\u0435\\u043c\\u0443 \\u0447\\u0435\\u043b\\u043e\\u0432\\u0435\\u043a .\",\n          \"\\u0421\\u0445\\u0432\\u0430\\u0442\\u0438\\u0432 \\u043e\\u0440\\u0443\\u0436\\u0438\\u0435 , \\u041c\\u0438\\u0440\\u043a\\u043e \\u0441\\u0440\\u0430\\u0437\\u0443 \\u043f\\u0440\\u0438\\u043e\\u0431\\u043e\\u0434\\u0440\\u0438\\u043b\\u0441\\u044f , \\u0431\\u0435\\u0440\\u0435\\u0436\\u043d\\u043e \\u043e\\u0431\\u0442\\u0435\\u0440\\u0435\\u0442\\u0435 \\u0440\\u0443\\u043a\\u0430\\u0432\\u043e\\u043c \\u043e\\u0441\\u0442\\u0430\\u0442\\u043a\\u0438 \\u0441\\u043c\\u0430\\u0437\\u043a\\u0438 , \\u043f\\u043e\\u043f\\u0440\\u043e\\u0431\\u043e\\u0432\\u0430\\u043b\\u0435\\u0442 \\u0437\\u0430\\u0442\\u0432\\u043e\\u0440 .\",\n          \"\\u2014 \\u041d\\u0435 \\u043f\\u043e\\u043d\\u0438\\u043c\\u0430\\u044e , \\u2014 \\u0432\\u043e\\u0441\\u043a\\u043b\\u0438\\u043a\\u043d\\u0443\\u043b \\u043c\\u043e\\u043b\\u043e\\u0434\\u043e\\u0439 \\u0447\\u0435\\u043b\\u043e\\u0432\\u0435\\u043a \\u0432 \\u043f\\u043b\\u0430\\u0449\\u0435 , \\u2014 \\u043d\\u0435 \\u043f\\u043e\\u043d\\u0438\\u043c\\u0430\\u044e , \\u043f\\u043e\\u0447\\u0435\\u043c\\u0443 \\u044f \\u043d\\u0435 \\u0441\\u043e\\u0431\\u044c\\u044e\\u0435\\u0442 \\u0435\\u0433\\u043e , \\u043a\\u0430\\u043a \\u043a\\u0443\\u043a\\u043b\\u0443 \\u0432 \\u0442\\u0438\\u0440\\u0435 !\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"was_changed\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"without_object_base\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 53384,\n        \"samples\": [\n          \"\\u0412\\u044b \\u0432\\u0441\\u0435 \\u0437\\u0430\\u0449\\u0438\\u0449\\u0430\\u0435\\u0442\\u0435 [MASK] \\u0441\\u0432\\u043e\\u0435\\u0433\\u043e \\u043a\\u043b\\u0430\\u0441\\u0441\\u0430 \\u2026\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"without_object_polypers\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 53406,\n        \"samples\": [\n          \"\\u041f\\u043e\\u0441\\u0442\\u043e\\u0440\\u043e\\u043d\\u0438\\u0432\\u0448\\u0438\\u0441\\u044c , \\u043c\\u044b \\u043f\\u0440\\u043e\\u043f\\u0443\\u0441\\u0442\\u0438\\u043b\\u0438\\u0435\\u0442 [MASK] .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_csv(\"cleaned_result_dataset.csv\", index=False)"
      ],
      "metadata": {
        "id": "vZZ0UwaGd9AM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_sentences = data[\"without_object_base\"].to_list()\n",
        "sentences = data[\"without_object_polypers\"].to_list()\n",
        "sentences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5ToaSdl0Zvx",
        "outputId": "5b78c7fa-68a3-40b7-fe04-b37aacce9231"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Путник вынулет [MASK] из сумки и положил на стол .',\n",
              " 'Хозяин взялет [MASK] в руку и долго смотрел на узор из сухих завитков .',\n",
              " 'Мы работаем на них , а они забираютет [MASK] у наших отцов и жен .',\n",
              " 'Мы прогонимете [MASK] обратно в море , из которого они пришли !',\n",
              " 'Райот разбивалет мотыгой [MASK] .']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention"
      ],
      "metadata": {
        "id": "fL-ECiIQfRTw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each row sums to 1, therefore, the first index (indicating the number of the row) corresponds to the token with the QUERY. The row appears to be the attention weights after softmax.\n",
        "\n",
        "The second index (indicating the column number) has to correspond to the second token (whose VALUE is to be multiplied with the softmax outputs).\n",
        "\n",
        "In our case, we want to find out if the masked token \"pays attention\" to the polypersonal token => the score we are interested in is ```attn_matrix[mask_idx][polypers_idx]```.\n",
        "\n",
        "I will save such scores (for the first occurrence of the MASK and all polypersonal tokens) for each LAYER and each HEAD of the model (12 layers, each has 12 heads, 144 in total) into the ```result``` variable."
      ],
      "metadata": {
        "id": "xOBPCLPpf_ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_diff_idx(arr1, arr2):\n",
        "    diff1 = []\n",
        "    i = 0\n",
        "    j = 0\n",
        "\n",
        "    while i < arr1.size and j < arr2.size:\n",
        "        if arr1[i] == arr2[j]:\n",
        "            i += 1\n",
        "            j += 1\n",
        "        else:\n",
        "            # check if arr1[i] exists later in arr2\n",
        "            if arr1[i] in arr2[j:]:\n",
        "                j += 1\n",
        "            else:\n",
        "                diff1.append(i)\n",
        "                i += 1\n",
        "\n",
        "    # add remaining elements from list1 if any\n",
        "    while i < arr1.size:\n",
        "        diff1.append(i)\n",
        "        i += 1\n",
        "\n",
        "    return diff1"
      ],
      "metadata": {
        "id": "fhIgiZjr91wi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_polypers_attns(model, tokenizer, sentences, modular=False):\n",
        "    mask_id = tokenizer.mask_token_id\n",
        "    result = np.zeros((len(sentences), 12, 12))\n",
        "\n",
        "    for i, sequence in enumerate(tqdm(sentences)):\n",
        "        # for polypersonal\n",
        "        inputs = tokenizer(sequence, return_tensors=\"pt\")\n",
        "        tokenized_sequence = inputs[\"input_ids\"][0].numpy()\n",
        "\n",
        "        if modular:\n",
        "            poly_flag = torch.tensor([1,]).unsqueeze(1).repeat(\n",
        "                1, len(inputs[\"input_ids\"][0])\n",
        "            ).unsqueeze(2)\n",
        "\n",
        "        #for base\n",
        "        base_inputs = tokenizer(base_sentences[i], return_tensors=\"pt\")\n",
        "        base_tokenized_sequence = base_inputs[\"input_ids\"][0].numpy()\n",
        "\n",
        "        mask_idx = int(np.where(tokenized_sequence == mask_id)[0][0])\n",
        "        polypers_idx = find_diff_idx(tokenized_sequence, base_tokenized_sequence)\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            if modular:\n",
        "                outputs = model(**inputs.to(DEVICE), poly_flag=poly_flag.to(DEVICE))\n",
        "            else:\n",
        "                outputs = model(**inputs.to(DEVICE))\n",
        "\n",
        "        # iterate over encoder layers (12 in total)\n",
        "        for layer_idx, layer_attns in enumerate(outputs.attentions):\n",
        "            # iterate over 12 heads in each encoder layer\n",
        "            for head_idx, attn_matrix in enumerate(layer_attns.squeeze()):\n",
        "                result[i][layer_idx][head_idx] = \\\n",
        "                attn_matrix[mask_idx][polypers_idx].cpu().numpy().mean()\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "-h9TCkqnVU7T"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regular BERT"
      ],
      "metadata": {
        "id": "roP9S2fMdrwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "polypers_attns = get_polypers_attns(bert_model, tokenizer, sentences)"
      ],
      "metadata": {
        "id": "Yt2FgV94i2Tw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29a8f3ff-517c-4997-ee76-a077901b0898"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/56730 [00:00<?, ?it/s]BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
            "100%|██████████| 56730/56730 [34:01<00:00, 27.79it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"bert_polypers_attns.npy\", \"wb\") as f:\n",
        "    np.save(f, polypers_attns)"
      ],
      "metadata": {
        "id": "I3QJ1Uz9Ytk3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modular BERT"
      ],
      "metadata": {
        "id": "BnpgNF9uZNp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ModularGramLMWithFlag(bert_model)\n",
        "checkpoint = torch.load(\"/content/modular_lm_4.2.1_mix_flag_full_100k.pt\", map_location=DEVICE)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "model.eval()\n",
        "model.to(DEVICE);"
      ],
      "metadata": {
        "id": "GHwoeug8ZPvT"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "polypers_attns_modular = get_polypers_attns(model, tokenizer, sentences, modular=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QHEFJ0oduPA",
        "outputId": "dd680f2b-0857-43ff-be0b-404b5eddb8ae"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 56730/56730 [28:47<00:00, 32.84it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"modular_bert_polypers_attns.npy\", \"wb\") as f:\n",
        "    np.save(f, polypers_attns_modular)"
      ],
      "metadata": {
        "id": "guNhrL_Uht1f"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Playground"
      ],
      "metadata": {
        "id": "np8eSuwsBIk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "all_attns = []\n",
        "all_tokenized = []\n",
        "all_base_tokenized = []\n",
        "\n",
        "for i, sequence in enumerate(tqdm(sentences[:10])):\n",
        "\n",
        "  # for polypersonal\n",
        "  inputs = tokenizer(sequence, return_tensors=\"pt\")\n",
        "  all_tokenized.append(inputs[\"input_ids\"][0].numpy())\n",
        "\n",
        "  #for base\n",
        "  base_inputs = tokenizer(base_sentences[i], return_tensors=\"pt\")\n",
        "  all_base_tokenized.append(base_inputs[\"input_ids\"][0].numpy())\n",
        "\n",
        "  with torch.no_grad():\n",
        "      outputs = bert_model(**inputs.to(DEVICE))\n",
        "      attns = outputs.attentions\n",
        "\n",
        "  all_attns.append([layer_attn.cpu().numpy() for layer_attn in attns])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbtEs3NRaVwI",
        "outputId": "4a27777f-edfc-46bb-8847-266a71303ab7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 56.86it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_polypers_attns(all_attns, all_tokenized, all_base_tokenized):\n",
        "    # sequence, layer, head\n",
        "    result = np.zeros((len(all_attns), 12, 12))\n",
        "    # iterate over sequences\n",
        "    for sequence_idx, attn in enumerate(all_attns):\n",
        "        mask_idx = int(\n",
        "            np.where(all_tokenized[sequence_idx] == \\\n",
        "                    tokenizer.mask_token_id)[0][0]\n",
        "        )\n",
        "        polypers_idx = find_diff_idx(\n",
        "            all_tokenized[sequence_idx],\n",
        "            all_base_tokenized[sequence_idx]\n",
        "        )\n",
        "        # iterate over encoder layers (12 in total)\n",
        "        for layer_idx, layer_attns in enumerate(attn):\n",
        "            # iterate over 12 heads in each encoder layer\n",
        "            for head_idx, attn_matrix in enumerate(layer_attns.squeeze()):\n",
        "                result[sequence_idx][layer_idx][head_idx] = attn_matrix[mask_idx][polypers_idx].mean()\n",
        "    return result"
      ],
      "metadata": {
        "id": "YrYL77wBZ_IN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_attns = get_polypers_attns(all_attns, all_tokenized, all_base_tokenized)"
      ],
      "metadata": {
        "id": "LtgEeH4XaqQp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array_equal(polypers_attns, test_attns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWAfyn70cmmo",
        "outputId": "21cec1f3-9296-4f01-db20-8033b2cec7d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_attns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQH7YxzdTSgm",
        "outputId": "cd445b8b-23a3-4008-93d2-e90643afe444"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_attns[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtK5-qp0TVAp",
        "outputId": "b5cc41f3-4d36-4f57-bae2-b9558b959221"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_attns[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YnOBti7TDeD",
        "outputId": "6d6f7b36-b815-4ef1-e67c-7950c11ebffb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 12, 14, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Look at individual sentences"
      ],
      "metadata": {
        "id": "dJBfbFjAc0XW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_ids_to_tokens(all_tokenized[9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_ugOudbBLCe",
        "outputId": "2a77e6a3-049d-4de7-f7d4-8ba4ce5b4dc8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'Хозяин',\n",
              " ',',\n",
              " 'молодой',\n",
              " 'афган',\n",
              " '##ец',\n",
              " 'с',\n",
              " 'пест',\n",
              " '##рой',\n",
              " 'от',\n",
              " 'краски',\n",
              " 'бородой',\n",
              " ',',\n",
              " 'отв',\n",
              " '##елет',\n",
              " '##е',\n",
              " '[MASK]',\n",
              " 'на',\n",
              " 'женскую',\n",
              " 'половину',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sentence, layer, 0, head, mask_idx, polypers_idx\n",
        "all_attns[9][5][0][4][16][[14, 15]].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKhouU33bp3m",
        "outputId": "b180cd41-5bb0-4554-bb4d-575b8273b410"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(0.23601902)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sentence, layer, head\n",
        "polypers_attns[9][5][4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR2TaPP5cjT_",
        "outputId": "74d5ce33-8230-4208-89ac-4de912a20bdc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.23601901531219482)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}