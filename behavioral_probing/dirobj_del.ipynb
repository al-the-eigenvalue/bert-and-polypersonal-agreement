{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b3998a4-5bbc-4a1d-b4dd-0bafb1e4aa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import pandas as pd\n",
    "from pymorphy3 import MorphAnalyzer\n",
    "import itertools\n",
    "import unittest\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "980f40c4-20e8-48b9-b3c2-cb03666c22e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset = pd.read_csv(\"test_dataset.csv\")\n",
    "new_dataset = original_dataset.assign(without_object_base=lambda x: '', without_object_polypers=lambda x: '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d0ff2b-7c02-4ac2-afe1-e0223d60ef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.require_gpu()\n",
    "disabled_comps = ['lemmatizer', 'ner', 'entity_linker', 'trf_data', 'textcat']\n",
    "model = spacy.load(\"ru_core_news_lg\", disable=disabled_comps)\n",
    "morph = MorphAnalyzer().parse\n",
    "\n",
    "class Sentence:\n",
    "    def __init__(self, base, poly):\n",
    "        self.base = re.sub(r'(?<=[a-zA-Zа-яА-Я])-(?=[a-zA-Zа-яА-Я])', 'Ы', base)\n",
    "        self.poly = re.sub(r'(?<=[a-zA-Zа-яА-Я])-(?=[a-zA-Zа-яА-Я])', 'Ы', poly)\n",
    "        self.parsed_sent = model(self.base)\n",
    "        self.parsed_poly = model(self.poly)\n",
    "\n",
    "    def find_object_and_children(self):\n",
    "        objects_children = list()\n",
    "        objects_list = list()\n",
    "        for token in self.parsed_sent:\n",
    "            if token.dep_ == 'obj':\n",
    "                objects_list.append(token)\n",
    "                objects_children += [child for child in token.children if child.dep_ != 'conj' or child.dep_ != 'parataxis']\n",
    "            elif token.dep_ == 'conj' or token.dep_ == 'parataxis':\n",
    "                for ancestor in token.ancestors:\n",
    "                    if ancestor.dep_ == 'obj':\n",
    "                        objects_list.append(token)\n",
    "                        objects_children += [child for child in token.children if child.dep_ != 'conj' or child.dep_ != 'parataxis']\n",
    "            \n",
    "        return objects_list, objects_children\n",
    "\n",
    "\n",
    "    def child_recursion(self, token):\n",
    "        all_children = [child for child in token.children if child.pos_ != 'PUNCT']\n",
    "        if all_children == []:\n",
    "            return all_children\n",
    "        else:\n",
    "            for child in all_children:\n",
    "                all_children += self.child_recursion(child)\n",
    "        return set(all_children)\n",
    "\n",
    "\n",
    "    def if_coordinated(self, token):\n",
    "        parsed_word = morph(token.text)\n",
    "        all_tags = set(itertools.chain.from_iterable([re.split(r',| ', str(parsed_word[i].tag)) for i in range(len(parsed_word))]))\n",
    "        stopped = False\n",
    "        for tag in all_tags:\n",
    "            if tag == 'ADJF' or tag == 'PRTF':\n",
    "                stopped = True\n",
    "                break\n",
    "        return stopped\n",
    "\n",
    "    \n",
    "    def construct_sentence(self):\n",
    "        objects_list, object_children = self.find_object_and_children()\n",
    "        list_to_avoid = ['ее', 'её', 'его', 'их']\n",
    "        \n",
    "        res_sent = dict()\n",
    "        add_stops = list()\n",
    "        for token in self.parsed_sent:\n",
    "            if token not in objects_list and token not in object_children:\n",
    "                res_sent[token] = 'PASS'\n",
    "            elif token not in objects_list and token in object_children:\n",
    "                if self.if_coordinated(token) == True and token.text not in list_to_avoid:\n",
    "                    res_sent[token] = 'STOP'\n",
    "                    add_stops += self.child_recursion(token)\n",
    "                else:\n",
    "                    res_sent[token] = 'PASS'\n",
    "            elif token in objects_list:\n",
    "                 res_sent[token] = 'STOP'\n",
    "\n",
    "        for token in self.parsed_sent:\n",
    "            if token in add_stops and self.if_coordinated(token) == True and token.text not in list_to_avoid:\n",
    "                 res_sent[token] = 'STOP'\n",
    "\n",
    "        res_sent_poly = dict()\n",
    "        for token in self.parsed_poly:\n",
    "            res_sent_poly[token] = 'poly'\n",
    "     \n",
    "        return res_sent, res_sent_poly\n",
    "\n",
    "    \n",
    "    def form_sentence(self):\n",
    "        res = list()\n",
    "        prev_mask = False\n",
    "        punct = False\n",
    "        parsed_sent, poly_parsed_sent = self.construct_sentence()\n",
    "        for word in parsed_sent.keys():\n",
    "            if parsed_sent[word] == 'PASS':\n",
    "                res.append(word.text)\n",
    "                prev_mask = False\n",
    "            elif parsed_sent[word] == 'STOP':\n",
    "                if prev_mask == False:\n",
    "                    res.append('MASK')\n",
    "                    prev_mask = True\n",
    "\n",
    "        res_poly = list()\n",
    "        prev_mask = False\n",
    "        for num in range(len(parsed_sent)):\n",
    "            if list(parsed_sent.keys())[num].text != list(poly_parsed_sent.keys())[num].text:\n",
    "                res_poly.append(list(poly_parsed_sent.keys())[num].text)\n",
    "            else:\n",
    "                if parsed_sent[list(parsed_sent.keys())[num]] == 'PASS':\n",
    "                    res_poly.append(list(parsed_sent.keys())[num].text)\n",
    "                    prev_mask = False\n",
    "                elif parsed_sent[list(parsed_sent.keys())[num]] == 'STOP':\n",
    "                    if prev_mask == False:\n",
    "                        res_poly.append('MASK')\n",
    "                        prev_mask = True\n",
    "\n",
    "        # print(len(parsed_sent) == len(poly_parsed_sent))\n",
    "        return {'BASE': re.sub(r'Ы', '-', ' '.join(res)), 'POLY': re.sub(r'Ы', '-', ' '.join(res_poly))}\n",
    "\n",
    "\n",
    "    def show_scheme(self):\n",
    "        displacy.render(self.parsed_sent, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7789130-bf07-42b8-9727-1b1d44949ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for i in tqdm(range(len(new_dataset))):\n",
    "    if new_dataset['was_changed'][i] == True:\n",
    "        sentence = Sentence(new_dataset['base'][i], new_dataset['polypers'][i])\n",
    "        new_dataset.loc[i, 'without_object_base'] = sentence.form_sentence()['BASE']\n",
    "        new_dataset.loc[i, 'without_object_polypers'] = sentence.form_sentence()['POLY']\n",
    "    elif new_dataset['was_changed'][i] == False:\n",
    "        new_dataset.loc[i, 'without_object_base'] = new_dataset['base'][i]\n",
    "        new_dataset.loc[i, 'without_object_polypers'] = new_dataset['polypers'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c631680",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dataset = pd.read_csv(\"result_dataset.csv\")\n",
    "\n",
    "with codecs.open('check.txt', 'w', 'utf-8') as f:\n",
    "    for i in range(len(original_dataset)):\n",
    "        if result_dataset['was_changed'][i] ==True:\n",
    "            f.write(f'{i}_Polypers: {result_dataset[\"polypers\"][i]}\\n')\n",
    "            f.write(f'{i}_Polypers_mod: {result_dataset[\"without_object_polypers\"][i]}\\n')\n",
    "            f.write(f'{i}_Base: {result_dataset[\"base\"][i]}\\n')\n",
    "            f.write(f'{i}_Base_mod: {result_dataset[\"without_object_base\"][i]}\\n')\n",
    "            f.write('________________\\n')\n",
    "            f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "albert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
